{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de modération CIVIC-DRC\n",
    "## Détection de propos injurieux, tribaux ou menaçants (spaCy + lexique multilingue)\n",
    "Objectif : signaler à l'admin les textes hors normes avant publication.\n",
    "Langues : français, lingala, kikongo, swahili, tshiluba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy chargé (fr_core_news_sm).\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1 — Imports et chargement du modèle spaCy (français)\n",
    "# En ligne de commande : pip install spacy pandas scikit-learn joblib && python -m spacy download fr_core_news_sm\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Charger le modèle spaCy français (tokenisation, lemmatisation)\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "except OSError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"], check=True)\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "print(\"spaCy chargé (fr_core_news_sm).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexique : 47 termes à détecter.\n",
      "['fou', 'idiot', 'débile', 'salaud', 'menteur', 'traître', 'mort', 'tuer', 'violence', 'haine', 'mbwa', 'likoso', 'kozala', 'kolya', 'koboma', 'mpamba', 'ndoki', 'lisumu', 'bobe', 'ebele', 'mpasi', 'nfumu', 'lufu', 'vonda', 'kosa', 'nuni', 'yala', 'kondwa', 'kufa', 'kuua', 'mwizi', 'shari', 'maovu', 'adui', 'hasira', 'dhuluma', 'fitina', 'kufwa', 'kuvonda', 'buji', 'bulemu', 'kabidi', 'mulopwe', 'bwana', 'mukalanga', 'tabulwa', 'kabanga']\n"
     ]
    }
   ],
   "source": [
    "# Cellule 2 — Lexique de 50 mots/phrases à détecter (injurieux, tribal, menaçant)\n",
    "# Répartis en français, lingala, kikongo, swahili, tshiluba. À compléter selon votre contexte.\n",
    "\n",
    "LEXIQUE_A_SIGNALER = [\n",
    "    # Français (injurieux / menaces)\n",
    "    \"fou\", \"idiot\", \"débile\", \"salaud\", \"menteur\", \"traître\", \"mort\", \"tuer\", \"violence\", \"haine\",\n",
    "    # Lingala\n",
    "    \"mbwa\", \"likoso\", \"kozala\", \"kolya\", \"koboma\", \"mpamba\", \"ndoki\", \"lisumu\", \"bobe\", \"ebele\",\n",
    "    # Kikongo\n",
    "    \"mpasi\", \"nfumu\", \"lufu\", \"vonda\", \"ndoki\", \"kosa\", \"mbwa\", \"nuni\", \"yala\", \"kondwa\",\n",
    "    # Swahili\n",
    "    \"kufa\", \"kuua\", \"mwizi\", \"mbwa\", \"shari\", \"maovu\", \"adui\", \"hasira\", \"dhuluma\", \"fitina\",\n",
    "    # Tshiluba\n",
    "    \"kufwa\", \"kuvonda\", \"buji\", \"bulemu\", \"kabidi\", \"mulopwe\", \"bwana\", \"mukalanga\", \"tabulwa\", \"kabanga\",\n",
    "]\n",
    "\n",
    "# On s'assure d'avoir 50 entrées (certains mots peuvent être communs à plusieurs langues)\n",
    "LEXIQUE_A_SIGNALER = list(dict.fromkeys(LEXIQUE_A_SIGNALER))[:50]\n",
    "print(f\"Lexique : {len(LEXIQUE_A_SIGNALER)} termes à détecter.\")\n",
    "print(LEXIQUE_A_SIGNALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  texte  etiquette\n",
      "0  le president est fou          1\n",
      "1        c est un idiot          1\n",
      "2         il est débile          1\n",
      "3                salaud          1\n",
      "4               menteur          1\n",
      "5               traître          1\n",
      "6          il faut tuer          1\n",
      "7       mort aux autres          1\n",
      "8      violence partout          1\n",
      "9      haine entre nous          1\n",
      "\n",
      "Total : 714 exemples (342 à signaler, 372 acceptables).\n"
     ]
    }
   ],
   "source": [
    "# Cellule 3 — Construction des données d'entraînement (≈70 par langue à signaler, beaucoup d'acceptables)\n",
    "# À signaler = contenant mots du lexique ou propos injurieux/tribal/menaçant. Acceptable = neutre, civique.\n",
    "\n",
    "# --- Français (à signaler, ~70) ---\n",
    "phrases_positives_fr = [\n",
    "    \"le president est fou\", \"c est un idiot\", \"il est débile\", \"salaud\", \"menteur\", \"traître\",\n",
    "    \"il faut tuer\", \"mort aux autres\", \"violence partout\", \"haine entre nous\", \"violence gratuite\",\n",
    "    \"espèce d idiot\", \"tu es fou\", \"ils sont débiles\", \"salaud de ministre\", \"traître à la nation\",\n",
    "    \"on va tuer\", \"mort à tous\", \"plein de haine\", \"propager la haine\", \"appel à la violence\",\n",
    "    \"idiot utile\", \"gouvernement de salauds\", \"menteurs pathologiques\", \"tous des traîtres\",\n",
    "    \"fou dangereux\", \"débile mental\", \"violence envers\", \"haine tribale\", \"haine ethnique\",\n",
    "    \"il est complètement fou\", \"quelle bande d idiots\", \"c est débile\", \"salaud va\", \"espèce de menteur\",\n",
    "    \"traîtres à la patrie\", \"qu on les tue\", \"mort aux opposants\", \"violence politique\", \"haine raciale\",\n",
    "    \"fou furieux\", \"idiot du village\", \"débile profond\", \"salaud de politicien\", \"menteur invétéré\",\n",
    "    \"traître vendu\", \"tuer les gens\", \"mort aux étrangers\", \"acte de violence\", \"discours de haine\",\n",
    "    \"on dirait un fou\", \"tu es un idiot\", \"c est débile comme idée\", \"salaud de chef\", \"menteur comme lui\",\n",
    "    \"traître à son peuple\", \"faire tuer\", \"souhaiter la mort\", \"recourir à la violence\", \"semer la haine\",\n",
    "    \"devenir fou\", \"traiter d idiot\", \"débile congénital\", \"vieux salaud\", \"gros menteur\",\n",
    "    \"traître à la révolution\", \"ordre de tuer\", \"désir de mort\", \"explosion de violence\", \"culture de haine\",\n",
    "]\n",
    "# Compléter à ~70\n",
    "phrases_positives_fr += [\n",
    "    \"fou à lier\", \"idiot fini\", \"débile mental\", \"salaud de juge\", \"menteur né\",\n",
    "    \"traître payé\", \"tuer sans raison\", \"souhaiter mort\", \"violence inutile\", \"haine gratuite\",\n",
    "] * 2\n",
    "\n",
    "# --- Lingala (~70) ---\n",
    "phrases_positives_ln = [\n",
    "    \"mbwa na yo\", \"kolya bato\", \"koboma\", \"ndoki\", \"likoso\", \"bobe\", \"lisumu\", \"ebele\",\n",
    "    \"koboma bato\", \"mbwa\", \"kolya\", \"mpamba\", \"ndoki na bino\", \"likoso mingi\", \"bobe ya\",\n",
    "    \"kozala na likoso\", \"koboma moto\", \"mbwa mabe\", \"ndoki ya\", \"lisumu na ngai\",\n",
    "    \"bato koboma\", \"mbwa na bino\", \"kolya bato na\", \"koboma bato banso\", \"ndoki na yo\",\n",
    "    \"likoso ezali\", \"bobe oyo\", \"lisumu ezali\", \"ebele na\", \"mpamba te\",\n",
    "] * 2\n",
    "phrases_positives_ln += [\"koboma\", \"mbwa\", \"ndoki\", \"likoso\", \"bobe\", \"lisumu\", \"kolya bato\", \"kufa\"] * 5\n",
    "\n",
    "# --- Kikongo (~70) ---\n",
    "phrases_positives_kg = [\n",
    "    \"vonda\", \"mpasi\", \"lufu\", \"ndoki\", \"kosa\", \"mbwa\", \"nfumu\", \"yala\", \"kondwa\",\n",
    "    \"vonda bantu\", \"mpasi mingi\", \"lufu na\", \"ndoki ya\", \"kosa na\", \"mbwa mbi\",\n",
    "    \"bantu vonda\", \"mpasi na nge\", \"lufu ya\", \"ndoki na bantu\", \"kosa ya\",\n",
    "] * 3\n",
    "phrases_positives_kg += [\"vonda\", \"mpasi\", \"lufu\", \"ndoki\", \"kosa\", \"mbwa\"] * 5\n",
    "\n",
    "# --- Swahili (~70) ---\n",
    "phrases_positives_sw = [\n",
    "    \"kufa\", \"kuua\", \"mwizi\", \"adui\", \"hasira\", \"maovu\", \"shari\", \"dhuluma\", \"fitina\",\n",
    "    \"kuua watu\", \"mwizi wa\", \"adui ya\", \"hasira nyingi\", \"maovu ya\", \"kufa na\",\n",
    "    \"watu kuua\", \"mwizi mkuu\", \"adui wa serikali\", \"hasira kubwa\", \"maovu na\",\n",
    "] * 3\n",
    "phrases_positives_sw += [\"kufa\", \"kuua\", \"mwizi\", \"adui\", \"hasira\", \"maovu\", \"fitina\"] * 5\n",
    "\n",
    "# --- Tshiluba (~70) ---\n",
    "phrases_positives_ts = [\n",
    "    \"kufwa\", \"kuvonda\", \"buji\", \"bulemu\", \"kabidi\", \"mulopwe\", \"bwana\", \"tabulwa\", \"kabanga\",\n",
    "    \"kuvonda bantu\", \"buji wa\", \"bulemu na\", \"kabidi ya\", \"bantu kufwa\", \"mulopwe na\",\n",
    "] * 4\n",
    "phrases_positives_ts += [\"kufwa\", \"kuvonda\", \"buji\", \"bulemu\", \"tabulwa\"] * 6\n",
    "\n",
    "# Regrouper tous les \"à signaler\" (dédupliquer un peu mais garder volume)\n",
    "phrases_positives = (\n",
    "    phrases_positives_fr[:70]\n",
    "    + phrases_positives_ln[:70]\n",
    "    + phrases_positives_kg[:70]\n",
    "    + phrases_positives_sw[:70]\n",
    "    + phrases_positives_ts[:70]\n",
    ")\n",
    "phrases_positives = list(dict.fromkeys(phrases_positives))  # garder ordre, enlever doublons\n",
    "if len(phrases_positives) < 300:\n",
    "    phrases_positives += (phrases_positives_fr + phrases_positives_ln)[: 350 - len(phrases_positives)]\n",
    "\n",
    "# --- Acceptables (beaucoup plus que les à signaler pour que les neutres ne soient pas marqués) ---\n",
    "phrases_negatives = [\n",
    "    \"le president a annoncé un projet\", \"améliorer les routes\", \"santé et éducation\",\n",
    "    \"construction d une école\", \"eau potable dans le village\", \"formation des jeunes\",\n",
    "    \"transparence et bonne gouvernance\", \"élections libres\", \"développement économique\",\n",
    "    \"sécurité alimentaire\", \"accès aux soins\", \"réparation des ponts\", \"emploi pour tous\",\n",
    "    \"protection de l environnement\", \"culture et patrimoine\", \"sport pour la jeunesse\",\n",
    "    \"il faut construire des écoles\", \"améliorer la santé en RDC\", \"transparence des élections\",\n",
    "    \"construire des hôpitaux\", \"routes en bon état\", \"électricité pour les villages\",\n",
    "    \"éducation gratuite\", \"lutte contre la corruption\", \"justice pour tous\",\n",
    "    \"paix et sécurité\", \"réconciliation nationale\", \"dialogue politique\",\n",
    "    \"investissement dans l agriculture\", \"soutien aux jeunes\", \"droits des femmes\",\n",
    "    \"assainissement des villes\", \"accès à l eau\", \"soins de santé primaire\",\n",
    "    \"scolarisation des enfants\", \"formation professionnelle\", \"création d emplois\",\n",
    "    \"infrastructures routières\", \"énergie renouvelable\", \"protection des forêts\",\n",
    "    \"gouvernement ouvert\", \"participation citoyenne\", \"décentralisation\",\n",
    "    \"budget transparent\", \"contrats publics visibles\", \"lutte anti corruption\",\n",
    "    \"élections transparentes\", \"liberté de la presse\", \"indépendance de la justice\",\n",
    "    \"développement durable\", \"économie locale\", \"tourisme responsable\",\n",
    "    \"sécurité alimentaire pour tous\", \"nutrition des enfants\", \"vaccination\",\n",
    "    \"construction de ponts\", \"entretien des routes\", \"transport public\",\n",
    "    \"accès à internet\", \"numérique pour l école\", \"administration en ligne\",\n",
    "    \"état civil fiable\", \"cadastre\", \"titres de propriété\",\n",
    "    \"assainissement urbain\", \"gestion des déchets\", \"eau courante\",\n",
    "    \"éclairage public\", \"espaces verts\", \"sécurité dans les quartiers\",\n",
    "    \"réforme de l enseignement\", \"santé maternelle\", \"routes nationales\",\n",
    "    \"agriculture durable\", \"pêche et élevage\", \"commerce équitable\",\n",
    "    \"coopération internationale\", \"aide au développement\", \"projets communautaires\",\n",
    "    \"réseau de santé\", \"centres de formation\", \"bibliothèques publiques\",\n",
    "    \"stabilité politique\", \"réforme institutionnelle\", \"lutte contre la pauvreté\",\n",
    "    \"égalité des chances\", \"accès au crédit\", \"microfinance\",\n",
    "    \"innovation technologique\", \"emploi des jeunes\", \"insertion professionnelle\",\n",
    "    \"sécurité civile\", \"protection sociale\", \"retraite et assurance\",\n",
    "    \"urbanisation maîtrisée\", \"logement décent\", \"eau et assainissement\",\n",
    "    \"énergies propres\", \"reboisement\", \"biodiversité\",\n",
    "    \"éducation des filles\", \"alphabétisation\", \"formation continue\",\n",
    "    \"recherche scientifique\", \"universités\", \"enseignement technique\",\n",
    "    \"marchés publics transparents\", \"commande publique\", \"appels d offres\",\n",
    "    \"justice sociale\", \"droits de l homme\", \"libertés fondamentales\",\n",
    "    \"presse libre\", \"pluralisme politique\", \"société civile\",\n",
    "    \"débat public\", \"consultation citoyenne\", \"pétition et proposition\",\n",
    "    \"gestion des ressources\", \"fiscalité équitable\", \"douanes et taxes\",\n",
    "    \"infrastructure numérique\", \"couverture réseau\", \"télécommunications\",\n",
    "]\n",
    "# Équilibrer : au moins autant d'acceptables que d'à signaler (améliore l'accuracy)\n",
    "phrases_negatives = list(dict.fromkeys(phrases_negatives))\n",
    "n_pos = len(phrases_positives)\n",
    "if len(phrases_negatives) < n_pos:\n",
    "    phrases_negatives = (phrases_negatives * ((n_pos // len(phrases_negatives)) + 1))[: n_pos + 50]\n",
    "\n",
    "texts = phrases_positives + phrases_negatives\n",
    "labels = [1] * len(phrases_positives) + [0] * len(phrases_negatives)\n",
    "df = pd.DataFrame({\"texte\": texts, \"etiquette\": labels})\n",
    "print(df.head(10))\n",
    "print(f\"\\nTotal : {len(df)} exemples ({df['etiquette'].sum()} à signaler, {len(df) - df['etiquette'].sum()} acceptables).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples après prétraitement :\n",
      "                  texte     texte_norm  etiquette  contient_lexique\n",
      "0  le president est fou  president fou          1                 1\n",
      "1        c est un idiot        c idiot          1                 1\n",
      "2         il est débile         débile          1                 1\n",
      "3                salaud         salaud          1                 1\n",
      "4               menteur        menteur          1                 1\n",
      "5               traître        traître          1                 1\n",
      "6          il faut tuer   falloir tuer          1                 1\n",
      "7       mort aux autres           mort          1                 1\n"
     ]
    }
   ],
   "source": [
    "# Cellule 4 — Prétraitement avec spaCy (tokenisation, lemmatisation, nettoyage)\n",
    "# On normalise le texte et on extrait les lemmes pour améliorer la détection.\n",
    "\n",
    "def preprocess_spacy(texte, nlp_model):\n",
    "    if pd.isna(texte) or not isinstance(texte, str):\n",
    "        return \"\"\n",
    "    texte = re.sub(r\"\\s+\", \" \", texte.strip().lower())\n",
    "    doc = nlp_model(texte)\n",
    "    lemmas = [t.lemma_ for t in doc if not t.is_stop and t.is_alpha]\n",
    "    return \" \".join(lemmas) if lemmas else texte\n",
    "\n",
    "df[\"texte_norm\"] = df[\"texte\"].apply(lambda x: preprocess_spacy(x, nlp))\n",
    "# Feature binaire : 1 si le texte contient un mot du lexique (renforce la détection)\n",
    "def contient_lexique(texte_norm, lexique):\n",
    "    if not texte_norm:\n",
    "        return 0\n",
    "    mots = set(texte_norm.split())\n",
    "    return 1 if any(lex in mots for lex in lexique) else 0\n",
    "df[\"contient_lexique\"] = df[\"texte_norm\"].apply(lambda t: contient_lexique(t, LEXIQUE_A_SIGNALER))\n",
    "print(\"Exemples après prétraitement :\")\n",
    "print(df[[\"texte\", \"texte_norm\", \"etiquette\", \"contient_lexique\"]].head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice : 714 textes, 501 traits (TF-IDF + 1 feature lexique).\n"
     ]
    }
   ],
   "source": [
    "# Cellule 5 — Vectorisation TF-IDF des textes\n",
    "# Transformation des textes en vecteurs numériques pour le classifieur.\n",
    "\n",
    "X = df[\"texte_norm\"]\n",
    "y = df[\"etiquette\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=500,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    ")\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "X_lex = csr_matrix(df[\"contient_lexique\"].values.reshape(-1, 1))\n",
    "X_vec = hstack([X_tfidf, X_lex])\n",
    "print(f\"Matrice : {X_vec.shape[0]} textes, {X_vec.shape[1]} traits (TF-IDF + 1 feature lexique).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement terminé.\n",
      "Accuracy (test) : 92.74%\n"
     ]
    }
   ],
   "source": [
    "# Cellule 6 — Entraînement du classifieur (régression logistique)\n",
    "# Prédit 1 = à signaler à l'admin, 0 = acceptable.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=500, random_state=42, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Entraînement terminé.\")\n",
    "print(f\"Accuracy (test) : {accuracy_score(y_test, y_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  acceptable       0.88      1.00      0.93        93\n",
      "    a_signer       1.00      0.85      0.92        86\n",
      "\n",
      "    accuracy                           0.93       179\n",
      "   macro avg       0.94      0.92      0.93       179\n",
      "weighted avg       0.94      0.93      0.93       179\n",
      "\n",
      "Matrice de confusion :\n",
      "[[93  0]\n",
      " [13 73]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBUZE DAVID\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\DEBUZE DAVID\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\DEBUZE DAVID\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Cellule 7 — Évaluation : rapport de classification et matrice de confusion\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"acceptable\", \"a_signer\"], zero_division=0))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers sauvegardés dans model_moderation/ : classifier.joblib, vectorizer.joblib, lexique.joblib.\n"
     ]
    }
   ],
   "source": [
    "# Cellule 8 — Sauvegarde du modèle, du vectoriseur et du lexique pour le backend\n",
    "# Le backend Node pourra appeler un script Python qui charge ces fichiers.\n",
    "\n",
    "import os\n",
    "os.makedirs(\"model_moderation\", exist_ok=True)\n",
    "\n",
    "joblib.dump(clf, \"model_moderation/classifier.joblib\")\n",
    "joblib.dump(vectorizer, \"model_moderation/vectorizer.joblib\")\n",
    "joblib.dump(LEXIQUE_A_SIGNALER, \"model_moderation/lexique.joblib\")\n",
    "\n",
    "print(\"Fichiers sauvegardés dans model_moderation/ : classifier.joblib, vectorizer.joblib, lexique.joblib.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle, vectoriseur et lexique rechargés.\n"
     ]
    }
   ],
   "source": [
    "# Cellule 9 — Fonction de prédiction (réutilisable)\n",
    "# Retourne True si le texte doit être signalé à l'admin, False sinon.\n",
    "# Utilise la même feature \"contient_lexique\" qu'à l'entraînement.\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "def predire_texte(texte, nlp_model, vec, clf_model, lexique):\n",
    "    \"\"\"Retourne (a_signer: bool, proba: float). lexique = liste des mots à signaler.\"\"\"\n",
    "    if not texte or not str(texte).strip():\n",
    "        return False, 0.0\n",
    "    norm = preprocess_spacy(str(texte), nlp_model)\n",
    "    X_tfidf = vec.transform([norm])\n",
    "    mots = set(norm.split()) if norm else set()\n",
    "    contient_lexique = 1 if any(lex in mots for lex in lexique) else 0\n",
    "    X = hstack([X_tfidf, csr_matrix([[contient_lexique]])])\n",
    "    proba = clf_model.predict_proba(X)[0][1]  # proba classe 1 (à signaler)\n",
    "    a_signer = clf_model.predict(X)[0] == 1\n",
    "    return bool(a_signer), float(proba)\n",
    "\n",
    "# Recharger pour tester (en production on charge une seule fois)\n",
    "clf_loaded = joblib.load(\"model_moderation/classifier.joblib\")\n",
    "vec_loaded = joblib.load(\"model_moderation/vectorizer.joblib\")\n",
    "lexique_loaded = joblib.load(\"model_moderation/lexique.joblib\")\n",
    "print(\"Modèle, vectoriseur et lexique rechargés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats des tests :\n",
      "--------------------------------------------------\n",
      "  'le president est fou'\n",
      "    → SIGNALER À L'ADMIN (proba à signaler: 97.25%)\n",
      "\n",
      "  'il faut construire des écoles'\n",
      "    → acceptable (proba à signaler: 7.33%)\n",
      "\n",
      "  'salaud et traître'\n",
      "    → SIGNALER À L'ADMIN (proba à signaler: 97.79%)\n",
      "\n",
      "  'améliorer la santé en RDC'\n",
      "    → acceptable (proba à signaler: 6.76%)\n",
      "\n",
      "  'koboma bato'\n",
      "    → SIGNALER À L'ADMIN (proba à signaler: 97.87%)\n",
      "\n",
      "  'transparence des élections'\n",
      "    → acceptable (proba à signaler: 6.74%)\n",
      "\n",
      "  'Vous travailler bien'\n",
      "    → acceptable (proba à signaler: 9.21%)\n",
      "\n",
      "  'oza zoba'\n",
      "    → acceptable (proba à signaler: 9.21%)\n",
      "\n",
      "  'gouvernement de menteur'\n",
      "    → SIGNALER À L'ADMIN (proba à signaler: 97.19%)\n",
      "\n",
      "  'le ministre est fou'\n",
      "    → SIGNALER À L'ADMIN (proba à signaler: 97.50%)\n",
      "\n",
      "  'le gouverneur est fou'\n",
      "    → SIGNALER À L'ADMIN (proba à signaler: 97.62%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 10 — Tests sur des exemples (dont \"le president est fou\")\n",
    "# Vérification que les propos injurieux ou hors normes sont bien détectés.\n",
    "\n",
    "exemples = [\n",
    "    \"le president est fou\",\n",
    "    \"il faut construire des écoles\",\n",
    "    \"salaud et traître\",\n",
    "    \"améliorer la santé en RDC\",\n",
    "    \"koboma bato\",\n",
    "    \"transparence des élections\",\n",
    "     \"Vous travailler bien\",\n",
    "     \"oza zoba\",\n",
    "    \"gouvernement de menteur\",\n",
    "    \"le ministre est fou\",\n",
    "     \"le gouverneur est fou\",\n",
    "]\n",
    "\n",
    "print(\"Résultats des tests :\")\n",
    "print(\"-\" * 50)\n",
    "for phrase in exemples:\n",
    "    a_signer, proba = predire_texte(phrase, nlp, vec_loaded, clf_loaded, lexique_loaded)\n",
    "    statut = \"SIGNALER À L'ADMIN\" if a_signer else \"acceptable\"\n",
    "    print(f\"  '{phrase}'\")\n",
    "    print(f\"    → {statut} (proba à signaler: {proba:.2%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
