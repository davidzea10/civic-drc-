{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de modération CIVIC-DRC\n",
    "## Détection de propos injurieux, tribaux ou menaçants (spaCy + lexique multilingue)\n",
    "Objectif : signaler à l'admin les textes hors normes avant publication.\n",
    "Langues : français, lingala, kikongo, swahili, tshiluba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 1 — Imports et chargement du modèle spaCy (français)\n",
    "# En ligne de commande : pip install spacy pandas scikit-learn joblib && python -m spacy download fr_core_news_sm\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Charger le modèle spaCy français (tokenisation, lemmatisation)\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "except OSError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"], check=True)\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "print(\"spaCy chargé (fr_core_news_sm).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 2 — Lexique de 50 mots/phrases à détecter (injurieux, tribal, menaçant)\n",
    "# Répartis en français, lingala, kikongo, swahili, tshiluba. À compléter selon votre contexte.\n",
    "\n",
    "LEXIQUE_A_SIGNALER = [\n",
    "    # Français (injurieux / menaces)\n",
    "    \"fou\", \"idiot\", \"débile\", \"salaud\", \"menteur\", \"traître\", \"mort\", \"tuer\", \"violence\", \"haine\",\n",
    "    # Lingala\n",
    "    \"mbwa\", \"likoso\", \"kozala\", \"kolya\", \"koboma\", \"mpamba\", \"ndoki\", \"lisumu\", \"bobe\", \"ebele\",\n",
    "    # Kikongo\n",
    "    \"mpasi\", \"nfumu\", \"lufu\", \"vonda\", \"ndoki\", \"kosa\", \"mbwa\", \"nuni\", \"yala\", \"kondwa\",\n",
    "    # Swahili\n",
    "    \"kufa\", \"kuua\", \"mwizi\", \"mbwa\", \"shari\", \"maovu\", \"adui\", \"hasira\", \"dhuluma\", \"fitina\",\n",
    "    # Tshiluba\n",
    "    \"kufwa\", \"kuvonda\", \"buji\", \"bulemu\", \"kabidi\", \"mulopwe\", \"bwana\", \"mukalanga\", \"tabulwa\", \"kabanga\",\n",
    "]\n",
    "\n",
    "# On s'assure d'avoir 50 entrées (certains mots peuvent être communs à plusieurs langues)\n",
    "LEXIQUE_A_SIGNALER = list(dict.fromkeys(LEXIQUE_A_SIGNALER))[:50]\n",
    "print(f\"Lexique : {len(LEXIQUE_A_SIGNALER)} termes à détecter.\")\n",
    "print(LEXIQUE_A_SIGNALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 3 — Construction des données d'entraînement\n",
    "# Phrases contenant un mot du lexique → étiquette 1 (à signaler). Phrases neutres → 0 (acceptable).\n",
    "\n",
    "phrases_positives = [\n",
    "    \"le president est fou\", \"c est un idiot\", \"il faut tuer\", \"violence partout\", \"haine entre nous\",\n",
    "    \"mbwa na yo\", \"kolya bato\", \"koboma\", \"kufa\", \"kuua\", \"mwizi\", \"adui\", \"ndoki\", \"vonda\",\n",
    "    \"salaud de ministre\", \"menteur\", \"traître à la nation\", \"mort aux autres\", \"débile\",\n",
    "    \"mpasi mingi\", \"lufu\", \"hasira\", \"maovu\", \"bulemu\", \"fitina\", \"lisumu\", \"bobe\",\n",
    "]\n",
    "\n",
    "phrases_negatives = [\n",
    "    \"le president a annoncé un projet\", \"améliorer les routes\", \"santé et éducation\",\n",
    "    \"construction d une école\", \"eau potable dans le village\", \"formation des jeunes\",\n",
    "    \"transparence et bonne gouvernance\", \"élections libres\", \"développement économique\",\n",
    "    \"sécurité alimentaire\", \"accès aux soins\", \"réparation des ponts\", \"emploi pour tous\",\n",
    "    \"protection de l environnement\", \"culture et patrimoine\", \"sport pour la jeunesse\",\n",
    "]\n",
    "\n",
    "texts = phrases_positives + phrases_negatives\n",
    "labels = [1] * len(phrases_positives) + [0] * len(phrases_negatives)\n",
    "df = pd.DataFrame({\"texte\": texts, \"etiquette\": labels})\n",
    "print(df.head(10))\n",
    "print(f\"\\nTotal : {len(df)} exemples ({df['etiquette'].sum()} à signaler, {len(df) - df['etiquette'].sum()} acceptables).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 4 — Prétraitement avec spaCy (tokenisation, lemmatisation, nettoyage)\n",
    "# On normalise le texte et on extrait les lemmes pour améliorer la détection.\n",
    "\n",
    "def preprocess_spacy(texte, nlp_model):\n",
    "    if pd.isna(texte) or not isinstance(texte, str):\n",
    "        return \"\"\n",
    "    texte = re.sub(r\"\\s+\", \" \", texte.strip().lower())\n",
    "    doc = nlp_model(texte)\n",
    "    lemmas = [t.lemma_ for t in doc if not t.is_stop and t.is_alpha]\n",
    "    return \" \".join(lemmas) if lemmas else texte\n",
    "\n",
    "df[\"texte_norm\"] = df[\"texte\"].apply(lambda x: preprocess_spacy(x, nlp))\n",
    "print(\"Exemples après prétraitement :\")\n",
    "print(df[[\"texte\", \"texte_norm\", \"etiquette\"]].head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 5 — Vectorisation TF-IDF des textes\n",
    "# Transformation des textes en vecteurs numériques pour le classifieur.\n",
    "\n",
    "X = df[\"texte_norm\"]\n",
    "y = df[\"etiquette\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=500,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    ")\n",
    "\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "print(f\"Matrice TF-IDF : {X_vec.shape[0]} textes, {X_vec.shape[1]} traits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 6 — Entraînement du classifieur (régression logistique)\n",
    "# Prédit 1 = à signaler à l'admin, 0 = acceptable.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=500, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Entraînement terminé.\")\n",
    "print(f\"Accuracy (test) : {accuracy_score(y_test, y_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 7 — Évaluation : rapport de classification et matrice de confusion\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"acceptable\", \"a_signer\"]))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 8 — Sauvegarde du modèle, du vectoriseur et du lexique pour le backend\n",
    "# Le backend Node pourra appeler un script Python qui charge ces fichiers.\n",
    "\n",
    "import os\n",
    "os.makedirs(\"model_moderation\", exist_ok=True)\n",
    "\n",
    "joblib.dump(clf, \"model_moderation/classifier.joblib\")\n",
    "joblib.dump(vectorizer, \"model_moderation/vectorizer.joblib\")\n",
    "joblib.dump(LEXIQUE_A_SIGNALER, \"model_moderation/lexique.joblib\")\n",
    "\n",
    "print(\"Fichiers sauvegardés dans model_moderation/ : classifier.joblib, vectorizer.joblib, lexique.joblib.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 9 — Fonction de prédiction (réutilisable)\n",
    "# Retourne True si le texte doit être signalé à l'admin, False sinon.\n",
    "\n",
    "def predire_texte(texte, nlp_model, vec, clf_model):\n",
    "    \"\"\"Retourne (a_signer: bool, proba: float).\"\"\"\n",
    "    if not texte or not str(texte).strip():\n",
    "        return False, 0.0\n",
    "    norm = preprocess_spacy(str(texte), nlp_model)\n",
    "    X = vec.transform([norm])\n",
    "    proba = clf_model.predict_proba(X)[0][1]  # proba classe 1 (à signaler)\n",
    "    a_signer = clf_model.predict(X)[0] == 1\n",
    "    return bool(a_signer), float(proba)\n",
    "\n",
    "# Recharger pour tester (en production on charge une seule fois)\n",
    "clf_loaded = joblib.load(\"model_moderation/classifier.joblib\")\n",
    "vec_loaded = joblib.load(\"model_moderation/vectorizer.joblib\")\n",
    "print(\"Modèle et vectoriseur rechargés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 10 — Tests sur des exemples (dont \"le president est fou\")\n",
    "# Vérification que les propos injurieux ou hors normes sont bien détectés.\n",
    "\n",
    "exemples = [\n",
    "    \"le president est fou\",\n",
    "    \"il faut construire des écoles\",\n",
    "    \"salaud et traître\",\n",
    "    \"améliorer la santé en RDC\",\n",
    "    \"koboma bato\",\n",
    "    \"transparence des élections\",\n",
    "]\n",
    "\n",
    "print(\"Résultats des tests :\")\n",
    "print(\"-\" * 50)\n",
    "for phrase in exemples:\n",
    "    a_signer, proba = predire_texte(phrase, nlp, vec_loaded, clf_loaded)\n",
    "    statut = \"SIGNALER À L'ADMIN\" if a_signer else \"acceptable\"\n",
    "    print(f\"  '{phrase}'\")\n",
    "    print(f\"    → {statut} (proba à signaler: {proba:.2%})\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
